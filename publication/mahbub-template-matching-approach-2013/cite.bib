@article{mahbubTemplateMatchingApproach2013,
 abstract = {This paper proposes a novel approach for gesture recognition from motion depth images based on template matching. Gestures can be represented with image templates, which in turn can be used to compare and match gestures. The proposed method uses a single example of an action as a query to find similar matches and thus termed one-shot-learning gesture recognition. It does not require prior knowledge about actions, foreground/background segmentation, or any motion estimation or tracking. The proposed method makes a novel approach to separate different gestures from a single video. Moreover, this method is based on the computation of spaceâ€“time descriptors from the query video which measures the likeness of a gesture in a lexicon. These descriptor extraction methods include the standard deviation of the depth images of a gesture as well as the motion history image. Furthermore, two dimensional discrete Fourier transform is employed to reduce the effect of camera shift. The comparison is done based on correlation coefficient of the image templates and an intelligent classifier is proposed to ensure better recognition accuracy. Extensive experimentation is done on a very complicated and diversified dataset to establish the effectiveness of employing the proposed methods.},
 author = {Mahbub, Upal and Imtiaz, Hafiz and Roy, Tonmoy and Rahman, Md. Shafiur and Rahman Ahad, Md. Atiqur},
 doi = {10.1016/j.patrec.2012.09.014},
 issn = {0167-8655},
 journal = {Pattern Recognition Letters},
 keywords = {2D Fourier transform, Depth image, Gesture recognition, Motion history image},
 language = {en},
 month = {November},
 number = {15},
 pages = {1780--1788},
 series = {Smart Approaches for Human Action Recognition},
 title = {A template matching approach of one-shot-learning gesture recognition},
 url = {http://www.sciencedirect.com/science/article/pii/S0167865512002991},
 urldate = {2019-12-01},
 volume = {34},
 year = {2013}
}

